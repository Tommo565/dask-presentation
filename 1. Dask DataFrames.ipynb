{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dask DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Dask Client\n",
    "\n",
    "[Dask Client API Reference](https://distributed.dask.org/en/stable/api.html#distributed.Client)  \n",
    "[Dask Dataframe Tutorial](https://tutorial.dask.org/04_dataframe.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These settings took a bit of trial and error to avoid a mountain of memory leak messages!\n",
    "* My machine (Mac OSX) has 16 cores and 16MB of RAM.\n",
    "* See the 5. Dask Client Notebook for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\n",
    "    n_workers=4,\n",
    "    threads_per_worker=2,\n",
    "    memory_limit=\"4 GiB\"\n",
    ")\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the flights.csv dataframe 20 x bigger (Pandas)\n",
    "\n",
    "To allow for a more meaningful comparison, this concatanates the flights dataset 20 times, resulting in around 116m rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify columns to keep\n",
    "usecols = [\n",
    "    \"YEAR\", \"MONTH\", \"DAY\", \"FLIGHT_NUMBER\", \"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\",\n",
    "    \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\"\n",
    "]\n",
    "\n",
    "# Read the data in from csv\n",
    "df = pd.read_csv(\"./data/flights/flights.csv\", usecols=usecols)\n",
    "\n",
    "df_20 = df.copy()\n",
    "\n",
    "i = 1\n",
    "while i < 20:\n",
    "    df_20 = pd.concat([df_20, df])\n",
    "    i += 1\n",
    "\n",
    "df_20.to_csv(\"./data/flights/flights_limited_x20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the flights.csv dataframe 20 x bigger (Dask)\n",
    "\n",
    "You can also do it in Dask, which is a lot quicker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Specify columns to keep\n",
    "usecols = [\n",
    "    \"YEAR\", \"MONTH\", \"DAY\", \"FLIGHT_NUMBER\", \"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\",\n",
    "    \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\"\n",
    "]\n",
    "\n",
    "# Read the data in from csv\n",
    "df = dd.read_csv(\"./data/flights/flights.csv\", usecols=usecols)\n",
    "\n",
    "df_20 = df.copy()\n",
    "\n",
    "i = 1\n",
    "while i < 20:\n",
    "    df_20 = dd.concat([df_20, df])\n",
    "    i = i+1\n",
    "\n",
    "# Write to CSV\n",
    "df_20.to_csv(\"./data/flights/flights_limited_x20_csv\", index=False)\n",
    "\n",
    "# Write to JSON\n",
    "df_20.to_json(\n",
    "    filename=\"./data/flights/flights_limited_x20_json\",\n",
    "    orient=\"records\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Speed Test\n",
    "\n",
    "Testing the speed of some commonly used pandas functionality on our DataFrame, including:\n",
    "\n",
    "* Reading a CSV\n",
    "* Dropping na values\n",
    "* Converting to Datetime\n",
    "* Vectorised (across columns) sum\n",
    "* Dropping\n",
    "* Filtering\n",
    "* Groupby / sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_20 = pd.read_csv(\"./data/flights/flights_limited_x20.csv\")\n",
    "\n",
    "# Fill NA values\n",
    "df_20 = df_20.fillna(0)\n",
    "\n",
    "# Create a Date column\n",
    "df_20[\"DATE\"] = pd.to_datetime(df_20[[\"YEAR\", \"MONTH\", \"DAY\"]])\n",
    "\n",
    "df_20[\"TOTAL_DELAY\"] = (\n",
    "    df_20[['AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']].sum(axis=1)\n",
    ")\n",
    "\n",
    "# Drop Columns\n",
    "df_20 = df_20.drop([\"YEAR\", \"MONTH\", \"DAY\"], axis=1)\n",
    "\n",
    "# Perform Boolean Indexing (Where/Filter)\n",
    "df_20 = df_20[df_20[\"DATE\"] > pd.to_datetime(\"2015-01-01\")]\n",
    "\n",
    "print(df_20.shape)\n",
    "\n",
    "# Perform an aggregation\n",
    "tab = df_20.groupby([\"DATE\", \"FLIGHT_NUMBER\"]).sum()\n",
    "\n",
    "# Show the table\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask Speed Test\n",
    "\n",
    "The same functionality as the Pandas speed test, but in Dask. Note:\n",
    "* Replacing pd with a reference to `dask.dataframe`\n",
    "* Computing the code with `.compute()`. This converts an out-of-memory Dask DataFrame to an in-memory Pandas DataFrame.\n",
    "* Note that we call compute on `tab` and not `df_20`. `df_20` will still be processed as a dependency but it won't be stored in memory.\n",
    "* Ideally you should call compute just once on your final output (or not at all if writing data out).\n",
    "\n",
    "* A good Dask workflow is:\n",
    "    * Import \n",
    "    * Reduce (e.g. remove columns, filter data, remove NaN / outliers etc.)\n",
    "    * Transform (e.g. casting, new columns, functions etc.)\n",
    "    * Aggregate\n",
    "    * Compute / Write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "df_20 = dd.read_csv(\"./data/flights/flights_limited_x20.csv\")\n",
    "\n",
    "# Fill NA values\n",
    "df_20 = df_20.fillna(0)\n",
    "\n",
    "# Create a Date column\n",
    "df_20[\"DATE\"] = dd.to_datetime(df_20[[\"YEAR\", \"MONTH\", \"DAY\"]])\n",
    "\n",
    "df_20[\"TOTAL_DELAY\"] = (\n",
    "    df_20[['AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']].sum(axis=1)\n",
    ")\n",
    "\n",
    "# Drop Columns\n",
    "df_20 = df_20.drop([\"YEAR\", \"MONTH\", \"DAY\"], axis=1)\n",
    "\n",
    "# Perform Boolean Indexing (Where/Filter)\n",
    "df_20 = df_20[df_20[\"DATE\"] > pd.to_datetime(\"2015-01-01\")]\n",
    "\n",
    "print(df_20.shape)\n",
    "\n",
    "# Perform an aggregation\n",
    "tab = df_20.groupby([\"DATE\", \"FLIGHT_NUMBER\"]).sum()\n",
    "\n",
    "\n",
    "tab_out = tab.compute()\n",
    "tab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute two ways..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.dataframe import compute\n",
    "\n",
    "tab_out = compute(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_out = tab.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an un-computed DF\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the computed DF\n",
    "tab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the first 5 rows of an un-computed DF\n",
    "df_20.head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b113240f601ac29f59b2e1ba8c02c523d037a083f1225808d8f348674d974985"
  },
  "kernelspec": {
   "display_name": "dask-pres",
   "language": "python",
   "name": "dask-pres"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
